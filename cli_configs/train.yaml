defaults:
  - _self_
  - env: local
  - model: resnet
  - data: cifar10

teamname: 'debug'
output_subdir: ${exp_dir}/${teamname}/classification/${data.module.name}/checkpoints/${make_group_name:}
hydra:
  output_subdir: ${output_subdir}
  job:
    chdir: False
  run:
    dir: .

override hydra/hydra_logging: disable
override hydra/job_logging: disable

seed: False

model:
  optimizer: SGD
  sam: False  # set trainer.precision=32 if you use sam
  adaptive_sam: False  # set trainer.precision=32 if you use sam
  lr: 0.1
  nesterov: False
  scheduler: CosineAnneal
  T_max: ${trainer.max_epochs}
  warmstart: 0
  warmstart2: 0
  mixup: False
  mixup_alpha: 0.2
  weight_decay: 5e-4
  undecay_norm: False
  label_smoothing: 0.0
  stochastic_depth: False
  resnet_dropout: 0.0
  squeeze_excitation: False
  apply_shakedrop: False
  zero_init_residual: False
  input_dim: 2
  input_channels: 3
  task: 'Classification'
  subtask: 'multiclass'  # 'multilabel'
  metric_computation_mode: 'epochwise'
  result_plot: 'val'
  num_classes: ${data.num_classes}
  metrics: ${metrics}
  epochs: ${trainer.max_epochs}
  name: ${model_name_extractor:${model._target_}}
  compile: False
  classification_head_dropout: 0.0
  token_aggregation_method: cls_token
  pretrained: False
  finetune_method: full
  save_preds: True
    
data:
  module:
    random_batches: False
    num_workers: 12
    prepare_data_per_node: False
    fold: null
  num_classes: ???
  cv:
    k: 1  # 1=no Cross Validation

metrics:
  - 'acc'
  - 'f1'

val_only: False

trainer:
  _target_: lightning.pytorch.Trainer
  callbacks: 
    progressbar:
      _target_: lightning.pytorch.callbacks.RichProgressBar
    lr_monitor:
      _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: epoch
    checkpoint:
      _target_: lightning.pytorch.callbacks.ModelCheckpoint
      dirpath: ???
      filename: '{epoch}-{val_loss:.2f}'
      auto_insert_metric_name: True
    auto_plot:
      _target_: callbacks.auto_plot.AutoPlotCallback
      plot_every_n_epochs: 10
      save_dir: ${exp_dir}/${teamname}/classification/${data.module.name}/plots
      plot_format: png
      show_plots: False
  devices: 1
  accelerator: 'gpu'
  sync_batchnorm: False  # set to True if you use multiple GPUs
  enable_checkpointing: False
  max_epochs: 200
  benchmark: True
  deterministic: False
  precision: '16-mixed'
  enable_progress_bar: True
  strategy: 'ddp'
  logger: 
    _target_: lightning.pytorch.loggers.CSVLogger
    save_dir: ${exp_dir}/${teamname}/classification/${data.module.name}
    name: ${data.module.name}
  num_sanity_val_steps: 0
  accumulate_grad_batches: 1
  # Some useful trainer parameters for debugging
  #limit_train_batches: 0.1
  #limit_val_batches: 0.5
  #limit_test_batches: 0.25
  #gradient_clip_val: 0.5
  #log_every_n_steps: 50
